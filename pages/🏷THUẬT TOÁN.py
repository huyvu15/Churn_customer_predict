import streamlit as st
import pandas as pd 
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
import seaborn as sns
from sklearn.model_selection import train_test_split
from streamlit_extras.metric_cards import style_metric_cards
from sklearn.impute import SimpleImputer
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.metrics import accuracy_score, classification_report, roc_auc_score
from sklearn.neighbors import KNeighborsClassifier
from sklearn.preprocessing import MinMaxScaler
from sklearn.pipeline import Pipeline
from imblearn.combine import SMOTEENN
import time
from xgboost import XGBClassifier
from sklearn.ensemble import RandomForestClassifier


#from query import *
st.set_option('deprecation.showPyplotGlobalUse', False)

#navicon and header
st.set_page_config(page_title="Dashboard", page_icon="üìà", layout="wide")  

with open('style.css')as f:
    st.markdown(f"<style>{f.read()}</style>", unsafe_allow_html = True)

#current date
from datetime import datetime
current_datetime = datetime.now()
formatted_date = current_datetime.strftime('%Y-%m-%d')
formatted_day = current_datetime.strftime('%A')
 
st.header(" MACHINE LEARNING WORKFLOW | RANDOM FOREST ")
st.markdown(
 """
 <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.2/dist/css/bootstrap.min.css" rel="stylesheet">
 <hr>

<div class="card mb-3">
<div class="card">
  <div class="card-body">
    <h3 class="card-title"style="color:#007710;"><strong>‚è± S∆† L∆Ø·ª¢C V·ªÄ √ÅP D·ª§NG 3 THU·∫¨T TO√ÅN CHO HI·ªÜU NƒÇNG CAO NH·∫§T</strong></h3>
    <p class="card-text">Vi·∫øt ƒë√°nh gi√° s∆° b·ªô t·∫°i ƒë√¢y</p>
    <p class="card-text"><small class="text-body-secondary"> </small></p>
  </div>
</div>
</div>
 <style>
    [data-testid=stSidebar] {
         color: white;
         text-size:24px;
    }
</style>
""",unsafe_allow_html=True
)


with st.sidebar:
 st.markdown(f"<h4 class='text-success'>{formatted_day}: {formatted_date}</h4>Analytics Dashboard V: 01/2023<hr>", unsafe_allow_html=True)


df = pd.read_csv('churn.csv')

df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')
# T·∫°o m·ªôt imputer v·ªõi chi·∫øn l∆∞·ª£c thay th·∫ø l√† trung b√¨nh
imputer = SimpleImputer(missing_values=np.nan, strategy='mean')

# √Åp d·ª•ng imputer v√†o c·ªôt TotalCharges c·ªßa df
df['TotalCharges'] = imputer.fit_transform(df[['TotalCharges']])

for column in df.columns:
    if df[column].dtype == object:
        le = LabelEncoder()
        df[column] = le.fit_transform(df[column])

y = df['Churn']

# Start

with st.expander("‚¨á V·ªÄ D·ªÆ LI·ªÜU G·ªêC"):
    st.write("Examining the correlation between the independent variables (features) and the dependent variable before actually building and training a regression model. This is an important step in the initial data exploration and analysis phase to understand the relationships between variables.")
    st.dataframe(df)  # Hi·ªÉn th·ªã d·ªØ li·ªáu g·ªëc

df1 = df.drop(['customerID','Churn'], axis=1)
df1 = df.drop(columns=['gender', 'InternetService', 'MultipleLines',
                   'PhoneService', 'StreamingMovies','StreamingTV'])
with st.expander("‚¨á D·ªÆ LI·ªÜU SAU KHI ƒê√É X√ìA ƒêI C√ÅC C·ªòT"):
    st.write("Trong b∆∞·ªõc n√†y nh√≥m ƒë√£ x√≥a ƒëi c√°c c·ªôt kh√¥ng c·∫ßn thi·∫øt nh∆∞ 'customerID','Churn' (c·ªôt d·ª± ƒëo√°n), gender', 'InternetService', 'MultipleLines','PhoneService', 'StreamingMovies','StreamingTV ")
    st.dataframe(df)  # Hi·ªÉn th·ªã d·ªØ li·ªáu g·ªëc

with st.expander("‚¨á TH·ªêNG K√ä M√î T·∫¢ C·ª¶A D·ªÆ LI·ªÜU"):
    st.write("Th√™m text g√¨ ƒë√≥ v√†o ƒë√¢y")
    st.dataframe(df.describe())
    
with st.expander("‚¨á KH√ÅM PH√Å C√ÅC BI·∫æN S·ªê"):
    st.write("C√°c bi·ªÉu ƒë·ªì histogram v√† m√¥ t·∫£ chi ti·∫øt cho c√°c bi·∫øn s·ªë:")
    numeric_cols = [f for f in df.columns if df[f].dtype != "O"]
    for col in numeric_cols:
        st.write(f"### {col}")
        st.write(df[col].value_counts())
        st.write(df[col].describe())
        plt.figure(figsize=(4, 4))
        df[col].hist()
        plt.title(col)
        st.pyplot(plt)
with st.expander("m√î T·∫¢ "):
  st.caption("SeniorCitizen: 0 & 1")
  st.caption("Parter No 0 Yes 1")
  st.caption("Dependents No 0 Yes 1")
  st.caption("OnlineSecurity No 0 No internet service 1 Yes 2")
  st.caption("OnlineBackup No 0 No internet service 1 Yes 2")
  st.caption("DeviceProtection No 0 No internet service 1 Yes 2")
  st.caption("TechSupport No 0 No internet service 1 Yes 2")
  st.caption("Contact Month-to-month 0 One year 1 Two year 2")
  st.caption("PaperlessBilling No 0 Yes 1")
  st.caption("PaymentMethod Bank transfer (automatic) 0 Credit card (automatic) 1 Electronic check 2 Mailed check 3")
  
scaler = StandardScaler()
df = scaler.fit_transform(df)

with st.expander("‚¨á X·ª¨ L√ù OUTLIERS V√Ä MISSING VALUES"):
    df = pd.DataFrame(df)

    # Set up the matplotlib figure
    plt.figure(figsize=(10, 6))

    # Draw boxplots for each numerical variable
    sns.boxplot(data=df, orient="h", palette="Set2")

    # Add titles and labels
    plt.title("Boxplot of Variables in the Dataset")
    plt.xlabel("Value")

    # Display the plot
    plt.tight_layout()
    st.pyplot(plt)

    # Detect outliers using IQR or Z-score method
    Q1 = df.quantile(0.25)
    Q3 = df.quantile(0.75)
    IQR = Q3 - Q1

    # Find outliers using IQR
    outliers = ((df < (Q1 - 1.5 * IQR)) | (df > (Q3 + 1.5 * IQR))).any(axis=1)

    # Print rows with outliers
    outlier_rows = df[outliers]
    st.write("Rows with outliers:")
    st.dataframe(outlier_rows)

    # Handling outliers: Replace with NaN
    df[outliers] = np.nan

    # Handling missing values: Impute with mean
    df.fillna(df.mean(), inplace=True)

    # Print DataFrame after handling outliers
    st.write("DataFrame after handling outliers:")
    st.dataframe(df)

X = df

# UpSampling
sm = SMOTEENN()
X_res, y_res = sm.fit_resample(X, y)

# Ph√¢n t√°ch d·ªØ li·ªáu th√†nh t·∫≠p hu·∫•n luy·ªán v√† ki·ªÉm th·ª≠
X_train, X_test, y_train, y_test = train_test_split(X_res, y_res, test_size=0.2, random_state=42)

# ƒê·ªãnh nghƒ©a m√¥ h√¨nh K-Nearest Neighbors v·ªõi c√°c tham s·ªë c·ªë ƒë·ªãnh
model = KNeighborsClassifier(n_neighbors=5, weights='distance')

# T·∫°o m·ªôt pipeline
pipeline = Pipeline([
    ('scaler', MinMaxScaler()),  # Chu·∫©n h√≥a ƒë·∫∑c tr∆∞ng
    ('model', model)
])

# ƒêo th·ªùi gian b·∫Øt ƒë·∫ßu
start_time = time.time()

# Hu·∫•n luy·ªán pipeline tr√™n d·ªØ li·ªáu hu·∫•n luy·ªán
pipeline.fit(X_train, y_train)

# ƒêo th·ªùi gian k·∫øt th√∫c
end_time = time.time()
elapsed_time = end_time - start_time

# D·ª± ƒëo√°n tr√™n t·∫≠p ki·ªÉm th·ª≠
y_pred = pipeline.predict(X_test)

# T√≠nh ƒëi·ªÉm ƒë·ªô ch√≠nh x√°c
accuracy = accuracy_score(y_test, y_pred)
report = classification_report(y_test, y_pred, output_dict=True)
roc_auc = roc_auc_score(y_test, pipeline.predict_proba(X_test)[:, 1])

# Hi·ªÉn th·ªã k·∫øt qu·∫£
with st.expander("‚¨á K·∫æT QU·∫¢ PH√ÇN T√çCH M√î H√åNH K-NEAREST NEIGHBORS"):
    st.write(f"Model: K-Nearest Neighbors")
    st.write(f"Th·ªùi gian ch·∫°y: {elapsed_time:.4f} gi√¢y")
    st.write(f"ƒê·ªô ch√≠nh x√°c tr√™n t·∫≠p ki·ªÉm th·ª≠: {accuracy:.4f}")
    st.write("B√°o c√°o ph√¢n lo·∫°i:")
    st.json(report)
    st.write(f"Di·ªán t√≠ch d∆∞·ªõi ƒë∆∞·ªùng cong ROC (ROC AUC): {roc_auc:.4f}")

# XGBoost

# ƒê·ªãnh nghƒ©a m√¥ h√¨nh XGBoost v·ªõi c√°c tham s·ªë c·ªë ƒë·ªãnh
model1 = XGBClassifier(n_estimators=200, learning_rate=0.5)

# T·∫°o m·ªôt pipeline
pipeline = Pipeline([
    ('scaler', MinMaxScaler()),  # Chu·∫©n h√≥a ƒë·∫∑c tr∆∞ng
    ('model', model1)
])

# ƒêo th·ªùi gian b·∫Øt ƒë·∫ßu
start_time = time.time()

# Hu·∫•n luy·ªán pipeline tr√™n d·ªØ li·ªáu hu·∫•n luy·ªán
pipeline.fit(X_train, y_train)

# ƒêo th·ªùi gian k·∫øt th√∫c
end_time = time.time()
elapsed_time = end_time - start_time

# D·ª± ƒëo√°n tr√™n t·∫≠p ki·ªÉm th·ª≠
y_pred = pipeline.predict(X_test)

# T√≠nh ƒëi·ªÉm ƒë·ªô ch√≠nh x√°c
accuracy = accuracy_score(y_test, y_pred)
report = classification_report(y_test, y_pred, output_dict=True)
roc_auc = roc_auc_score(y_test, pipeline.predict_proba(X_test)[:, 1])

# Hi·ªÉn th·ªã k·∫øt qu·∫£
with st.expander("‚¨á K·∫æT QU·∫¢ PH√ÇN T√çCH M√î H√åNH XGBOOST"):
    st.write(f"Model: XGBoost")
    st.write(f"Th·ªùi gian ch·∫°y: {elapsed_time:.4f} gi√¢y")
    st.write(f"ƒê·ªô ch√≠nh x√°c tr√™n t·∫≠p ki·ªÉm th·ª≠: {accuracy:.4f}")
    st.write("B√°o c√°o ph√¢n lo·∫°i:")
    st.json(report)
    st.write(f"Di·ªán t√≠ch d∆∞·ªõi ƒë∆∞·ªùng cong ROC (ROC AUC): {roc_auc:.4f}")


model2 = RandomForestClassifier(max_depth=None, n_estimators=150)

# T·∫°o m·ªôt pipeline
pipeline = Pipeline([
    ('scaler', MinMaxScaler()),  # Chu·∫©n h√≥a ƒë·∫∑c tr∆∞ng
    ('model', model2)
])

# ƒêo th·ªùi gian b·∫Øt ƒë·∫ßu
start_time = time.time()

# Hu·∫•n luy·ªán pipeline tr√™n d·ªØ li·ªáu hu·∫•n luy·ªán
pipeline.fit(X_train, y_train)

# ƒêo th·ªùi gian k·∫øt th√∫c
end_time = time.time()
elapsed_time = end_time - start_time

# D·ª± ƒëo√°n tr√™n t·∫≠p ki·ªÉm th·ª≠
y_pred = pipeline.predict(X_test)

# T√≠nh ƒëi·ªÉm ƒë·ªô ch√≠nh x√°c
accuracy = accuracy_score(y_test, y_pred)
report = classification_report(y_test, y_pred, output_dict=True)
roc_auc = roc_auc_score(y_test, pipeline.predict_proba(X_test)[:, 1])

# Hi·ªÉn th·ªã k·∫øt qu·∫£
with st.expander("‚¨á K·∫æT QU·∫¢ PH√ÇN T√çCH M√î H√åNH RANDOM FOREST"):
    st.write(f"Model: Random Forest")
    st.write(f"Th·ªùi gian ch·∫°y: {elapsed_time:.4f} gi√¢y")
    st.write(f"ƒê·ªô ch√≠nh x√°c tr√™n t·∫≠p ki·ªÉm th·ª≠: {accuracy:.4f}")
    st.write("B√°o c√°o ph√¢n lo·∫°i:")
    st.json(report)
    st.write(f"Di·ªán t√≠ch d∆∞·ªõi ƒë∆∞·ªùng cong ROC (ROC AUC): {roc_auc:.4f}")

# End
